{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Playground for invoice processing with OpenAI API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2c74f97d95499de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define AWS invoice and credit record model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fbfc5f572e8cdea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define a new Pydantic model with field descriptions and tailored for AWS Invoice/Credit Record.\n",
    "class AwsInvoiceCredit(BaseModel):\n",
    "    file_name: str = Field(description=\"AWS Invoice PDF file name.\")\n",
    "    doit_payer_id: str = Field(description=\"Doit Payer ID. Can be extracted from the parent folder name.\")\n",
    "    aws_account_number: str = Field(description=\"AWS Account number.\")\n",
    "    address_company: str = Field(description=\"Address or Bill to Address company name. Use first line of the address. Usually, it is the company name.\")\n",
    "    address_attn: str = Field(description=\"Address or Bill to Address ATTN. Use second line of the address. Usually, it is the name of the person.\")\n",
    "    address_country: str = Field(description=\"Bill to address country. Use last line of the address. Usually, it is the country name. Convert short country code to a full country name.\")\n",
    "    amazon_company_name: str = Field(description=\"Amazon Web Services company name. Usually, it is Amazon Web Services, Inc. but can be different for different countries.\")\n",
    "    amazon_company_branch: Optional[str] = Field(default=\"\", description=\"Amazon Web Services company branch. Usually, it is after Amazon Web Services EMEA SARL but can be different for different countries; leave empty if not present\")\n",
    "    document_type: str = Field(description=\"Document Type. Can be 'Invoice' or 'Credit Note' only. Credit Note can be Credit Memo or Credit Adjustment Note.\")\n",
    "    billing_period: str = Field(description=\"Billing Period; Two dates separated by a dash; leave empty if not present\")\n",
    "    tax_registration_number: Optional[str] = Field(default=\"\", description=\"Tax Registration Number; ABN Number; GST Number; GST/HST Registration number; Issued To; usually the next number after AWS Account Number; leave empty if not present\")\n",
    "    invoice_number: str = Field(description=\"Invoice Number from the Invoice Summary\")\n",
    "    invoice_date: Optional[str] = Field(default=\"\", description=\"Invoice Date from the Invoice Summary.\")\n",
    "    original_invoice_number: Optional[str] = Field(default=\"\", description=\"Original Invoice Number from the Invoice Summary of Credit Memo/Note; leave empty if not present\")\n",
    "    original_invoice_date: Optional[str] = Field(default=\"\", description=\"Original Invoice Date from the Invoice Adjustment Summary of Credit Memo/Note.\")\n",
    "    total_amount: float = Field(description=\"Total Amount from the Invoice Summary; without currency; add minus sign if parentheses around or has a minus prefix\")\n",
    "    total_amount_currency: str = Field(description=\"Total Amount Currency from the Invoice Summary; use currency code instead of symbol\")\n",
    "    total_vat_tax_amount: Optional[float] = Field(default=None, description=\"Total VAT/Tax Amount from the Invoice Summary; without currency; add minus sign if parentheses around or has a minus prefix\")\n",
    "    total_vat_tax_currency: Optional[str] = Field(default=\"\", description=\"VAT/Tax Currency from the Invoice Summary; use currency code instead of symbol\")\n",
    "    net_charges_usd: Optional[float] = Field(default=None, description=\"USD Net Charges (After Credits/Discounts, excl. Tax) in USD from the Invoice Summary; without currency; add minus sign if parentheses around or has a minus prefix; leave empty if not present\")\n",
    "    net_charges_non_usd: Optional[float] = Field(default=None, description=\"Net Charges (After Credits/Discounts, excl. Tax) in local currency (not USD) from the Invoice Summary; without currency; add minus sign if parentheses around or has a minus prefix; leave empty if not present\")\n",
    "    net_charges_currency: Optional[str] = Field(default=\"\", description=\"Net Charges local currency (not USD); use currency code instead of symbol; leave empty if not present\")\n",
    "    vat_percentage: Optional[float] = Field(default=None, description=\"Extract VAT percent (without % sign) from one of these fields: VAT - <number>%; VAT in <percent>; GST amount at <percent>; HST Amount at <percent>; leave empty if not present or not a number between 0 and 100\")\n",
    "    exchange_rate: Optional[float] = Field(default=None, description=\"Exchange Rate from the Invoice Summary Table (1 USD = ?); leave empty if not found\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0853b598ffe5aec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_footer(text):\n",
    "    # remove everything after one of the following lines (including the line itself)\n",
    "    lines = [\n",
    "        \"* May include estimated US sales tax, VAT, ST, GST and CT.\",\n",
    "    ]\n",
    "    for line in lines:\n",
    "        if line in text:\n",
    "            return text.split(line)[0]\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "400b04f485187cbe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# scan all documents in the folder (recursively)\n",
    "def scan_folder(folder):\n",
    "    documents = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                loader = PyMuPDFLoader(os.path.join(root, file))\n",
    "                data = loader.load()\n",
    "                invoice = remove_footer(data[0].page_content)\n",
    "                # get parent folder name\n",
    "                parent_folder = os.path.basename(os.path.dirname(os.path.join(root, file)))\n",
    "                # extract doit payer id from the parent folder name\n",
    "                payer_id = parent_folder.split(\"_\")[1]\n",
    "                # add file name to the invoice\n",
    "                invoice = f\"File name: {file}\\nDoiT payer id: {payer_id}\\n\" + invoice\n",
    "                documents.append(invoice)\n",
    "    return documents\n",
    "\n",
    "all_documents = scan_folder(\"./data/12-2023\")\n",
    "print(f\"Found {len(all_documents)} documents\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b40949817b79d55"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "import textwrap\n",
    "\n",
    "async def extract_data(model, document, sem=asyncio.Semaphore(1)):\n",
    "    async with sem:\n",
    "        # Update the prompt to match the new query and desired format.\n",
    "        try:\n",
    "            # Instantiate the parser with the new model.\n",
    "            parser = PydanticOutputParser(pydantic_object=AwsInvoiceCredit)\n",
    "            # Get the file name from the first line of the document\n",
    "            file_name = document.split(\"\\n\")[0].split(\":\")[1].strip()\n",
    "            # Update the prompt to match the new query and desired format.\n",
    "            prompt = PromptTemplate(\n",
    "                template=textwrap.dedent(\n",
    "                    \"\"\"\n",
    "                    Extract data from the AWS Invoice or Credit document into a flat JSON object.\n",
    "                    {format_instructions}\n",
    "                    {request}\n",
    "                    <document>\n",
    "                    {invoice}\n",
    "                    <document>\n",
    "                    \n",
    "                    JSON:\n",
    "                    \"\"\"\n",
    "                ),\n",
    "                input_variables=[\"request\", \"invoice\"],\n",
    "                partial_variables={\n",
    "                    \"format_instructions\": parser.get_format_instructions(),\n",
    "                },\n",
    "            )\n",
    "            # Generate the input using the updated prompt.\n",
    "            parsing_request = textwrap.dedent(\n",
    "                \"\"\"\n",
    "                Return the extracted fields in the valid JSON format: only JSON objects and arrays are allowed without any comments or other text.\n",
    "                Convert all dates to \"Month name Day, Year\" format with no leading zeros.\n",
    "                Keep it as simple as possible and ensure the JSON is valid. \n",
    "                Skip the fields that are not present in the invoice.\n",
    "                Be careful with the currency symbols, which are not always in the invoice.\n",
    "                Try to extract the fields even if the invoice format differs and the fields are not in the same order. \n",
    "                My job depends on it! And I will be very grateful to you! Will pay you an extra 1000$ if you do it without errors!\n",
    "                \"\"\"\n",
    "            )\n",
    "            chain = LLMChain(llm=model, prompt=prompt)\n",
    "            retries = 2 # number of retries\n",
    "            while retries > 0:\n",
    "                try:\n",
    "                    output = await chain.arun(request=parsing_request, invoice=document)\n",
    "                    # remove everything before the first { and after the last }\n",
    "                    output = output[output.find(\"{\"):output.rfind(\"}\")+1]\n",
    "                    parsed = parser.parse(output)\n",
    "                    return parsed\n",
    "                except Exception as e:\n",
    "                    retries -= 1\n",
    "                    if retries == 0:\n",
    "                        raise Exception(f\"Error processing document {file_name}: {e}\")\n",
    "        except Exception as ex:\n",
    "            # returning and not raising the exception to continue processing other documents\n",
    "            return Exception(f\"Error processing document {file_name}: {ex}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d621692a5131827",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select LLM model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d1b3f0674d29c20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import Bedrock\n",
    "\n",
    "def get_model(model_name=\"gpt-4-1106-preview\", model_kwargs=None):\n",
    "    model = None\n",
    "    if model_name.startswith(\"gpt-\"):\n",
    "        # OpenAI API\n",
    "        model = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            temperature=0,\n",
    "            max_tokens=4096,\n",
    "        )\n",
    "    else:\n",
    "        # Bedrock API\n",
    "        client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "        model = Bedrock(\n",
    "            model_id=model_name, \n",
    "            client=client,\n",
    "            model_kwargs=model_kwargs,\n",
    "            )\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398fd70e0d677f1f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Instantiate the semaphore to limit the number of concurrent requests.\n",
    "# Approximate number of tokens per request is 1000-1500, so 50 requests will be 75k tokens\n",
    "# a single request takes 10 seconds, so 30 concurrent requests can lead to 180 requests per minute\n",
    "# 180 * 1500 = 270k tokens per minute (TPM) should be within the 600k TPM limit\n",
    "sem = asyncio.Semaphore(50)\n",
    "\n",
    "# measure time\n",
    "start = time.time()\n",
    "\n",
    "# Instantiate the LLM model.\n",
    "# llm = get_model(\"amazon.titan-text-express-v1\")\n",
    "llm = get_model()\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Loop over the max documents (all by default)\n",
    "max_docs = len(all_documents)\n",
    "tasks = []\n",
    "for i, doc in enumerate(all_documents[:max_docs]):\n",
    "    # Extract data from the document (async)\n",
    "    tasks.append(extract_data(llm, doc, sem))\n",
    "\n",
    "# measure time\n",
    "start = time.time()\n",
    "\n",
    "# Create a CSV file and write the results as they become available\n",
    "with open('invoices.csv', 'w') as f:\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        result = await future\n",
    "        if isinstance(result, Exception):\n",
    "            print(result)\n",
    "        else:\n",
    "            # Convert the result to a DataFrame and append it to the CSV file\n",
    "            try:\n",
    "                record = result.model_dump()\n",
    "                df_temp = pd.DataFrame.from_dict(record, orient='index').transpose()\n",
    "                df_temp.to_csv(f, header=f.tell()==0, index=False)\n",
    "                print(f\"Added record for: {record['file_name']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving record: {e}\")\n",
    "                \n",
    "\n",
    "# measure time\n",
    "end = time.time()\n",
    "print(f\"Time elapsed: {end - start} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b280c014877462da",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DEBUG functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14c699458ab767ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# DEBUG: process a single document\n",
    "async def process_document_file(file):\n",
    "    # llm = get_model(\"meta.llama2-70b-chat-v1\", {'temperature': 0, 'top_p': 1, 'max_gen_len': 2048})\n",
    "    llm = get_model()\n",
    "    loader = PyMuPDFLoader(file)\n",
    "    data = loader.load()\n",
    "    invoice = remove_footer(data[0].page_content)\n",
    "    # get parent folder name\n",
    "    parent_folder = os.path.basename(os.path.dirname(file))\n",
    "    # get file name only\n",
    "    file_name = os.path.basename(file)\n",
    "    # extract doit payer id from the parent folder name\n",
    "    payer_id = parent_folder.split(\"_\")[1]\n",
    "    # add file name to the invoice\n",
    "    invoice = f\"File name: {file_name}\\nDoiT payer id: {payer_id}\\n\" + invoice\n",
    "    print(invoice)\n",
    "    result = await extract_data(llm, invoice)\n",
    "    if isinstance(result, Exception):\n",
    "        print(result)\n",
    "    else:\n",
    "        print(result.model_dump())\n",
    "    \n",
    "await process_document_file(\"data/12-2023/457849337198_doitintl-payer-1919/2023-12-01_Invoice_EUINNL23_655056.pdf\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1fbe1df7e54dd09",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('prompts/llama.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Replace '\\n' with actual newline character\n",
    "content = content.replace('\\\\n', '\\n')\n",
    "content = content.replace('\\\\\"', '\"')\n",
    "\n",
    "with open('prompts/llama.txt', 'w') as file:\n",
    "    file.write(content)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e887a1d7d789898e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to the input CSV file and the path to the output sorted CSV file\n",
    "input_file_path = 'invoices-300.csv'\n",
    "output_file_path = 'sorted_invoices-300.csv'\n",
    "\n",
    "# Read the CSV file into a list of dictionaries, where each dictionary represents a row\n",
    "rows = []\n",
    "with open(input_file_path, 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    header = csv_reader.fieldnames\n",
    "    for row in csv_reader:\n",
    "        rows.append(row)\n",
    "\n",
    "# Sort the list of dictionaries based on the value of the first column (string)\n",
    "sorted_rows = sorted(rows, key=lambda x: x[header[0]])\n",
    "\n",
    "# Write the sorted rows back to a new CSV file\n",
    "with open(output_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n",
    "    \n",
    "    # Write the header\n",
    "    csv_writer.writeheader()\n",
    "    \n",
    "    # Write the sorted rows\n",
    "    for row in sorted_rows:\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "print(f\"The CSV file has been sorted alphabetically based on the first column and saved to {output_file_path}.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30d57e6b285621d2",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
