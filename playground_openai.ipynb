{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Playground for invoice processing with OpenAI API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2c74f97d95499de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define AWS invoice and credit record model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fbfc5f572e8cdea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define a new Pydantic model with field descriptions and tailored for AWS Invoice/Credit Record.\n",
    "class AwsInvoiceCredit(BaseModel):\n",
    "    file_name: str = Field(description=\"AWS Invoice PDF file name.\")\n",
    "    doit_payer_id: str = Field(description=\"Doit Payer ID. Can be extracted from the parent folder name.\")\n",
    "    aws_account_number: str = Field(description=\"AWS Account number.\")\n",
    "    address_company: str = Field(description=\"Address or Bill to Address company name. Use first line of the address. Usually, it is the company name.\")\n",
    "    address_attn: str = Field(description=\"Address or Bill to Address ATTN. Use second line of the address. Usually, it is the name of the person.\")\n",
    "    address_country: str = Field(description=\"Bill to address country. Use last line of the address. Usually, it is the country name. Convert short country code to a full country name.\")\n",
    "    document_type: str = Field(description=\"Document Type. Can be Invoice or Credit Note. Credit Note can be Credit Memo or Credit Adjustment Note.\")\n",
    "    billing_period: str = Field(description=\"Billing Period; Two dates separated by a dash; leave empty if not present\")\n",
    "    tax_registration_number: str = Field(default=None, description=\"Tax Registration Number; ABN Number; GST/HST Registration number; leave empty if not present\")\n",
    "    invoice_number: str = Field(description=\"Invoice Number from the Invoice Summary\")\n",
    "    invoice_date: str = Field(default=None, description=\"Invoice Date from the Invoice Summary\")\n",
    "    original_invoice_number: str = Field(default=None, description=\"Original Invoice Number from the Invoice Summary of Credit Memo/Note; leave empty if not present\")\n",
    "    original_invoice_date: str = Field(default=None, description=\"Original Invoice Date from the Invoice Adjustment Summary of Credit Memo/Note; leave empty if not present\")\n",
    "    total_amount: float = Field(description=\"Total Amount from the Invoice Summary; without currency; add minus sign if parentheses around or has a minus prefix\")\n",
    "    total_amount_currency: str = Field(description=\"Total Amount Currency from the Invoice Summary; use currency code instead of symbol\")\n",
    "    total_vat_tax_amount: float = Field(default=None, description=\"Total VAT/Tax Amount from the Invoice Summary; without currency; add minus sign if parentheses around or has a minus prefix\")\n",
    "    total_vat_tax_currency: str = Field(default=None, description=\"VAT/Tax Currency from the Invoice Summary; use currency code instead of symbol\")\n",
    "    vat_percentage: float = Field(default=None, description=\"VAT Percentage from the Invoice Summary Table; VAT - <number>%; GST amount at <number>%; HST Amount at <number>%; leave empty if not present\")\n",
    "    exchange_rate: float = Field(default=None, description=\"Exchange Rate from the Invoice Summary Table (1 USD = ?); leave empty if not found\")\n",
    "   \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:28:40.796163Z",
     "start_time": "2023-12-24T11:28:40.794921Z"
    }
   },
   "id": "e0853b598ffe5aec",
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the OpenAI model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d1b3f0674d29c20"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.0,\n",
    "    max_tokens=2048,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:21:32.411246Z",
     "start_time": "2023-12-24T11:21:32.394890Z"
    }
   },
   "id": "398fd70e0d677f1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_footer(text):\n",
    "    # remove everything after one of the following lines (including the line itself)\n",
    "    lines = [\n",
    "        \"* May include estimated US sales tax, VAT, ST, GST and CT.\",\n",
    "        \"Amazon Web Services EMEA SARL\",\n",
    "        \"Amazon Web Services Australia Pty Ltd\",\n",
    "        \"AMAZON WEB SERVICES EMEA SARL\",\n",
    "        \"Amazon Web Services Canada, Inc.\",\n",
    "        \"Amazon Web Services EMEA SARL, Luxembourg, Zweigniederlassung ZÃ¼rich\",\n",
    "    ]\n",
    "    for line in lines:\n",
    "        if line in text:\n",
    "            return text.split(line)[0]\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "400b04f485187cbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# scan all documents in the folder (recursively)\n",
    "def scan_folder(folder):\n",
    "    documents = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                loader = PyMuPDFLoader(os.path.join(root, file))\n",
    "                data = loader.load()\n",
    "                invoice = remove_footer(data[0].page_content)\n",
    "                # get parent folder name\n",
    "                parent_folder = os.path.basename(os.path.dirname(os.path.join(root, file)))\n",
    "                # extract doit payer id from the parent folder name\n",
    "                payer_id = parent_folder.split(\"_\")[1]\n",
    "                # add file name to the invoice\n",
    "                invoice = f\"File name: {file}\\nDoiT payer id: {payer_id}\\n\" + invoice\n",
    "                documents.append(invoice)\n",
    "    return documents\n",
    "\n",
    "all_documents = scan_folder(\"./data\")\n",
    "print(f\"Found {len(all_documents)} documents\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b40949817b79d55"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Instantiate the parser with the new model.\n",
    "parser = PydanticOutputParser(pydantic_object=AwsInvoiceCredit)\n",
    "\n",
    "def extract_data(model, document):\n",
    "    # Update the prompt to match the new query and desired format.\n",
    "    try:\n",
    "        prompt = PromptTemplate(\n",
    "            template=textwrap.dedent(\n",
    "                \"\"\"\n",
    "                Extract data from the AWS Invoice or Credit document into a flat JSON object.\n",
    "                {format_instructions}\n",
    "                {request}\n",
    "                <document>\n",
    "                {invoice}\n",
    "                <document>\n",
    "                JSON:\n",
    "                \"\"\"\n",
    "            ),\n",
    "            input_variables=[\"request\", \"invoice\"],\n",
    "            partial_variables={\n",
    "                \"format_instructions\": parser.get_format_instructions(),\n",
    "            },\n",
    "        )\n",
    "        # Generate the input using the updated prompt.\n",
    "        parsing_request = textwrap.dedent(\n",
    "            \"\"\"\n",
    "            Return the extracted fields in the valid JSON format: only JSON objects and arrays are allowed without any comments or other text. \n",
    "            Keep it as simple as possible and ensure the JSON is valid. \n",
    "            Skip the fields that are not present in the invoice.\n",
    "            Be careful with the currency symbols, which are not always in the invoice.\n",
    "            Try to extract the fields even if the invoice format differs and the fields are not in the same order. \n",
    "            My job depends on it! And I will be very grateful to you! Will pay you an extra 1000$ if you do it without errors!\n",
    "            \"\"\"\n",
    "        )\n",
    "        _input = prompt.format_prompt(request=parsing_request, invoice=document)\n",
    "        output = model(_input.to_messages())\n",
    "        parsed = parser.parse(output.content)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:28:46.303374Z",
     "start_time": "2023-12-24T11:28:46.302106Z"
    }
   },
   "id": "d621692a5131827",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed document 1 of 100\n",
      "Processed document 2 of 100\n",
      "Processed document 3 of 100\n",
      "Processed document 4 of 100\n",
      "Processed document 5 of 100\n",
      "Processed document 6 of 100\n",
      "Processed document 7 of 100\n",
      "Processed document 8 of 100\n",
      "Processed document 9 of 100\n",
      "Processed document 10 of 100\n",
      "Processed document 11 of 100\n",
      "Processed document 12 of 100\n",
      "Processed document 13 of 100\n",
      "Processed document 14 of 100\n",
      "Processed document 15 of 100\n",
      "Processed document 16 of 100\n",
      "Processed document 17 of 100\n",
      "Processed document 18 of 100\n",
      "Processed document 19 of 100\n",
      "Processed document 20 of 100\n",
      "Processed document 21 of 100\n",
      "Processed document 22 of 100\n",
      "Processed document 23 of 100\n",
      "Processed document 24 of 100\n",
      "Processed document 25 of 100\n",
      "Processed document 26 of 100\n",
      "Processed document 27 of 100\n",
      "Processed document 28 of 100\n",
      "Processed document 29 of 100\n",
      "Processed document 30 of 100\n",
      "Processed document 31 of 100\n",
      "Processed document 32 of 100\n",
      "Processed document 33 of 100\n",
      "Processed document 34 of 100\n",
      "Processed document 35 of 100\n",
      "Processed document 36 of 100\n",
      "Processed document 37 of 100\n",
      "Processed document 38 of 100\n",
      "Processed document 39 of 100\n",
      "Processed document 40 of 100\n",
      "Processed document 41 of 100\n",
      "Processed document 42 of 100\n",
      "Processed document 43 of 100\n",
      "Processed document 44 of 100\n",
      "Processed document 45 of 100\n",
      "Processed document 46 of 100\n",
      "Processed document 47 of 100\n",
      "Processed document 48 of 100\n",
      "Processed document 49 of 100\n",
      "Processed document 50 of 100\n",
      "Processed document 51 of 100\n",
      "Processed document 52 of 100\n",
      "Processed document 53 of 100\n",
      "Processed document 54 of 100\n",
      "Processed document 55 of 100\n",
      "Processed document 56 of 100\n",
      "Processed document 57 of 100\n",
      "Processed document 58 of 100\n",
      "Processed document 59 of 100\n",
      "Processed document 60 of 100\n",
      "Processed document 61 of 100\n",
      "Processed document 62 of 100\n",
      "Processed document 63 of 100\n",
      "Processed document 64 of 100\n",
      "Processed document 65 of 100\n",
      "Processed document 66 of 100\n",
      "Processed document 67 of 100\n",
      "Processed document 68 of 100\n",
      "Processed document 69 of 100\n",
      "Processed document 70 of 100\n",
      "Processed document 71 of 100\n",
      "Processed document 72 of 100\n",
      "Processed document 73 of 100\n",
      "Processed document 74 of 100\n",
      "Processed document 75 of 100\n",
      "Processed document 76 of 100\n",
      "Processed document 77 of 100\n",
      "Processed document 78 of 100\n",
      "Processed document 79 of 100\n",
      "Processed document 80 of 100\n",
      "Processed document 81 of 100\n",
      "Processed document 82 of 100\n",
      "Processed document 83 of 100\n",
      "Processed document 84 of 100\n",
      "Processed document 85 of 100\n",
      "Processed document 86 of 100\n",
      "Processed document 87 of 100\n",
      "Processed document 88 of 100\n",
      "Processed document 89 of 100\n",
      "Processed document 90 of 100\n",
      "Processed document 91 of 100\n",
      "Processed document 92 of 100\n",
      "Processed document 93 of 100\n",
      "Processed document 94 of 100\n",
      "Processed document 95 of 100\n",
      "Processed document 96 of 100\n",
      "Processed document 97 of 100\n",
      "Processed document 98 of 100\n",
      "Processed document 99 of 100\n",
      "Processed document 100 of 100\n",
      "Time elapsed: 881.7154552936554 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import time\n",
    "\n",
    "# measure time\n",
    "start = time.time()\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over the first max documents\n",
    "max = 100\n",
    "for i, doc in enumerate(all_documents[:max]):\n",
    "    try:\n",
    "        # Extract data from the document\n",
    "        result = extract_data(llm, doc)\n",
    "        # Append the result to the list\n",
    "        results.append(result.model_dump())\n",
    "        print(f\"Processed document {i+1} of {max}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Failed to process document {i+1} of {max}\")\n",
    "    \n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pandas.DataFrame.from_dict(results)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv(\"invoices.csv\", index=False)\n",
    "\n",
    "# measure time\n",
    "end = time.time()\n",
    "print(f\"Time elapsed: {end - start} seconds\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:48:32.182493Z",
     "start_time": "2023-12-24T11:33:50.463255Z"
    }
   },
   "id": "fdf9645b23734c2b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e3adf5afb4dc94e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
